{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import codecs\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Annotation(object):\n",
    "    def __init__(self):\n",
    "        self.start_index = -1\n",
    "        self.end_index = -1\n",
    "        self.type = ''\n",
    "        self.spanned_text = ''\n",
    "        \n",
    "    # adding this so that pyConText's HTML markup can work seamlessly\n",
    "    def getSpan(self):\n",
    "        return (self.start_index, self.end_index)\n",
    "    \n",
    "    def getCategory(self):\n",
    "        # pyConText graph objects actually expect a list here\n",
    "        return [self.type]\n",
    "\n",
    "class AnnotatedDocument(object):\n",
    "    def __init__(self):\n",
    "        self.text = ''\n",
    "        self.annotations = []\n",
    "        self.positive_label = -1\n",
    "        \n",
    "def read_brat_annotations(lines):\n",
    "    annotations = []\n",
    "    # BRAT FORMAT is:\n",
    "    # NUMBER[TAB]TYPE[SPACE]START_INDEX[SPACE]END_INDEX[SPACE]SPANNED_TEXT\n",
    "    for line in lines:\n",
    "        line = str(line)\n",
    "        tab_tokens = line.split('\\t')\n",
    "        space_tokens = tab_tokens[1].split()\n",
    "        anno = Annotation()\n",
    "        anno.spanned_text = tab_tokens[-1]\n",
    "        anno.type = space_tokens[0]\n",
    "        anno.start_index = int(space_tokens[1])\n",
    "        anno.end_index = int(space_tokens[2])\n",
    "        annotations.append(anno)\n",
    "    return annotations\n",
    "        \n",
    "def read_annotations(archive_file, force_redownload = False):\n",
    "    print('Reading annotations from file : ' + archive_file)\n",
    "    filename = archive_file.split('/')[-1]\n",
    "    \n",
    "    if force_redownload or not os.path.isfile(filename):\n",
    "        print('Downloading remote file : '+ archive_file)\n",
    "        urllib.request.urlretrieve(archive_file, filename)\n",
    "    \n",
    "    annotated_doc_map = {}\n",
    "    \n",
    "    print('Opening local file : ' + filename)\n",
    "    z = zipfile.ZipFile(filename, \"r\")\n",
    "    zinfo = z.namelist()\n",
    "    for name in zinfo:\n",
    "        if name.endswith('.txt') or name.endswith('.ann'):\n",
    "            basename = name.split('.')[0]\n",
    "            if basename not in annotated_doc_map:\n",
    "                annotated_doc_map[basename] = AnnotatedDocument()\n",
    "            anno_doc = annotated_doc_map[basename]\n",
    "            # handle text and BRAT annotation files (.ann) differently\n",
    "            if name.endswith('.txt'):\n",
    "                with z.open(name) as f1:\n",
    "                    anno_doc.text = f1.read().decode('utf8')\n",
    "            else:\n",
    "                with z.open(name) as f1:\n",
    "                    # handle this as utf8 or we get back byte arrays\n",
    "                    anno_doc.annotations = read_brat_annotations(codecs.iterdecode(f1, 'utf8'))\n",
    "                    \n",
    "    # now let's finally assign a 0 or 1 to each document based on whether we see our expected type for the pneumonia label\n",
    "    for key, anno_doc in annotated_doc_map.items():\n",
    "        annos = anno_doc.annotations\n",
    "        anno_doc.positive_label = 0\n",
    "        for anno in annos:\n",
    "            if anno.type == 'DOCUMENT_PNEUMONIA_YES':\n",
    "                anno_doc.positive_label = 1\n",
    "                    \n",
    "    return list(annotated_doc_map.values())\n",
    "\n",
    "def calculate_prediction_metrics(gold_docs, prediction_function):\n",
    "    gold_labels = [x.positive_label for x in gold_docs]\n",
    "    pred_labels = []\n",
    "    for gold_doc in gold_docs:\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        pred_labels.append(pred_label)\n",
    "        \n",
    "    # now let's use scikit-learn to compute some metrics\n",
    "    precision = sklearn.metrics.precision_score(gold_labels, pred_labels)\n",
    "    recall = sklearn.metrics.recall_score(gold_labels, pred_labels)\n",
    "    f1 = sklearn.metrics.f1_score(gold_labels, pred_labels)\n",
    "    # let's use Pandas to make a confusion matrix for us\n",
    "    confusion_matrix_df = pd.crosstab(pd.Series(gold_labels, name = 'Actual'), \n",
    "                                      pd.Series(pred_labels, name = 'Predicted'))\n",
    "    \n",
    "    print('Precision : {0}'.format(precision))\n",
    "    print('Recall : {0}'.format(recall))\n",
    "    print('F1: {0}'.format(f1))\n",
    "    \n",
    "    print('Confusion Matrix : ')\n",
    "    print(confusion_matrix_df)\n",
    "    \n",
    "annotated_docs = read_annotations('https://github.com/burgersmoke/DeCART_2017_rulebased_NLP/raw/master/data/BRAT/BratTestArchive.zip')\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_docs)))\n",
    "\n",
    "total_positives = 0\n",
    "for anno_doc in annotated_docs:\n",
    "    if anno_doc.positive_label:\n",
    "        total_positives += 1\n",
    "    \n",
    "print('Total Positive Pneumonia Documents : {0}'.format(total_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions to highlight annotations from BRAT\n",
    "def mark_text(txt,nodes,colors = {\"name\":\"red\",\"pet\":\"blue\"},default_color=\"black\"):\n",
    "    from pyConTextNLP.display.html import __insert_color\n",
    "    # this function had to be copied and modified from pyConTextNLP.display.html.mark_text \n",
    "    # so that the default_color could be passed through\n",
    "    if not nodes:\n",
    "        return txt\n",
    "    else:\n",
    "        n = nodes.pop(-1)\n",
    "        return mark_text(__insert_color(txt,\n",
    "                                        n.getSpan(),\n",
    "                                        colors.get(n.getCategory()[0],default_color)),\n",
    "                         nodes,\n",
    "                         colors=colors,\n",
    "                         # this was not being passed through \n",
    "                        default_color = default_color)\n",
    "    \n",
    "def pneumonia_html_markup(anno_doc):\n",
    "    from pyConTextNLP.display.html import __sort_by_span\n",
    "    # this bit mimics 'mark_document_with_html' from pyConTextNLP.display.html\n",
    "    colors = {}\n",
    "    colors['DOCUMENT_PNEUMONIA_YES'] = 'red'\n",
    "    colors['DOCUMENT_PNEUMONIA_NO'] = 'green'\n",
    "    colors['SPAN_POSITIVE_PNEUMONIA_EVIDENCE'] = 'orange'\n",
    "    default_color = 'red'\n",
    "    html = \"\"\"<p> {0} </p>\"\"\".format(\" \".join([mark_text(anno_doc.text,\n",
    "                                                 __sort_by_span(anno_doc.annotations),\n",
    "                                                 colors=colors,\n",
    "                                                 default_color=default_color)]))\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's find the document with the most annotations\n",
    "most_annotated_doc = None\n",
    "for anno_doc in annotated_docs:\n",
    "    \n",
    "    for anno in anno_doc.annotations:\n",
    "        print(anno.getCategory())\n",
    "    \n",
    "    if most_annotated_doc is None or len(anno_doc.annotations) > len(most_annotated_doc.annotations):\n",
    "        most_annotated_doc = anno_doc\n",
    "        print('Most Annotations so far : {}'.format(len(most_annotated_doc.annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's display one of our documents in HTML\n",
    "display(HTML(pneumonia_html_markup(most_annotated_doc).replace('\\n', '<br>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's first illustrate a naive baseline by always prediction NO pneumonia (i.e. 0)\n",
    "def naive_negative_pneumonia_prediction(text):\n",
    "    return 0\n",
    "    \n",
    "print('Predicting and validating the naive baseline of always predicting NO')\n",
    "calculate_prediction_metrics(annotated_docs, naive_negative_pneumonia_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's first illustrate a naive baseline by always prediction NO pneumonia (i.e. 0)\n",
    "def naive_positive_pneumonia_prediction(text):\n",
    "    return 1\n",
    "    \n",
    "print('Predicting and validating the naive baseline of always predicting YES')\n",
    "calculate_prediction_metrics(annotated_docs, naive_positive_pneumonia_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's try a very naive simulated baseline to assign positive Pneumonia anytime the work \"pneumonia\" appears in a document\n",
    "def naive_pneumonia_keyword_prediction(text):\n",
    "    if 'pneumonia' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print('Predicting and validating the naive PNEUMONIA keyword baseline')\n",
    "calculate_prediction_metrics(annotated_docs, naive_pneumonia_keyword_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's try another one where we use a class to store some \"keywords\"\n",
    "class KeywordClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.keywords = set()\n",
    "    def predict(self, text):\n",
    "        prediction = 0\n",
    "        for keyword in self.keywords:\n",
    "            if keyword in text:\n",
    "                prediction = 1\n",
    "        return prediction\n",
    "    \n",
    "keyword_classifier = KeywordClassifier()\n",
    "# let's load in some manual keywords...\n",
    "keyword_classifier.keywords.add('positive')\n",
    "keyword_classifier.keywords.add('confirmed')\n",
    "keyword_classifier.keywords.add('probable')\n",
    "\n",
    "print('Predicting and validating a classifier which uses some keywords above')\n",
    "calculate_prediction_metrics(annotated_docs, keyword_classifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE : Below this point will likely be split into another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyConTextNLP\n",
    "import pyConTextNLP.pyConTextGraph as pyConText\n",
    "import pyConTextNLP.itemData as itemData\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that we have downloaded NLTK tokenizer data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = itemData.instantiateFromCSVtoitemData(\n",
    "    \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/lexical_kb_05042016.tsv\")\n",
    "targets = itemData.instantiateFromCSVtoitemData(\n",
    "    \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/utah_crit.tsv\")\n",
    "\n",
    "print('Total Modifiers Loaded : [{0}]'.format(len(modifiers)))\n",
    "print('Total Targets Loaded : [{0}]'.format(len(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markup_sentence(s, modifiers, targets, prune_inactive=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    markup = pyConText.ConTextMarkup()\n",
    "    markup.setRawText(s)\n",
    "    markup.cleanText()\n",
    "    markup.markItems(modifiers, mode=\"modifier\")\n",
    "    markup.markItems(targets, mode=\"target\")\n",
    "    markup.pruneMarks()\n",
    "    markup.dropMarks('Exclusion')\n",
    "    # apply modifiers to any targets within the modifiers scope\n",
    "    markup.applyModifiers()\n",
    "    markup.pruneSelfModifyingRelationships()\n",
    "    if prune_inactive:\n",
    "        markup.dropInactiveModifiers()\n",
    "    return markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again, let's grab the most human annotated document\n",
    "# let's find the document with the most annotations\n",
    "most_annotated_doc = None\n",
    "for anno_doc in annotated_docs:\n",
    "    \n",
    "    for anno in anno_doc.annotations:\n",
    "        print(anno.getCategory())\n",
    "    \n",
    "    if most_annotated_doc is None or len(anno_doc.annotations) > len(most_annotated_doc.annotations):\n",
    "        most_annotated_doc = anno_doc\n",
    "        print('Most Annotations so far : {}'.format(len(most_annotated_doc.annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyConText.ConTextDocument()\n",
    "\n",
    "sentences = nltk.sent_tokenize(most_annotated_doc.text.lower())\n",
    "print('About to process {0} sentences...'.format(len(sentences)))\n",
    "\n",
    "results = []\n",
    "for s in sentences:\n",
    "    #print(s)\n",
    "    #print('*******************')\n",
    "    m = markup_sentence(s, modifiers=modifiers, targets=targets)\n",
    "    results.append(m)\n",
    "\n",
    "for r in results:\n",
    "    context.addMarkup(r)\n",
    "    \n",
    "print('Document marked up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare some colors for displaying any markup we might see\n",
    "clrs = {\\\n",
    "    \"pneumonia\": \"blue\",\n",
    "    \"pneumothorax\": \"blue\",\n",
    "    \"definite_negated_existence\": \"red\",\n",
    "    \"probable_negated_existence\": \"indianred\",\n",
    "    \"ambivalent_existence\": \"orange\",\n",
    "    \"probable_existence\": \"forestgreen\",\n",
    "    \"definite_existence\": \"green\",\n",
    "    \"historical\": \"goldenrod\",\n",
    "    \"indication\": \"pink\",\n",
    "    \"acute\": \"golden\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(pyConTextNLP.display.html.mark_document_with_html(context,colors = clrs, default_color=\"black\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what this looks like in XML\n",
    "print(context.getXML())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
